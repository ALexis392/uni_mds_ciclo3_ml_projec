{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ad9f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸ“Š FASE 3: EVALUATION\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ðŸ“Š EVALUATION - Credit Card Fraud Detection\n",
    "EvaluaciÃ³n final del mejor modelo en test set\n",
    "- Threshold optimization\n",
    "- Precision-Recall analysis\n",
    "- Final metrics\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, roc_curve, precision_recall_curve,\n",
    "    classification_report\n",
    ")\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“Š FASE 3: EVALUATION\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41da7d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] Cargando datos y modelos entrenados...\n",
      "âœ… Test set cargado: (85443, 32)\n",
      "   LegÃ­timas: 85295, Fraudes: 148\n",
      "âœ… Modelos cargados:\n",
      "   - Logistic Regression\n",
      "   - Random Forest\n",
      "   - XGBoost\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. CARGAR DATOS Y MODELOS\n",
    "# ============================================================================\n",
    "print(\"\\n[1] Cargando datos y modelos entrenados...\")\n",
    "\n",
    "# Cargar splits\n",
    "X_test = pd.read_csv('../data/training/X_test.csv')\n",
    "y_test = pd.read_csv('../data/training/y_test.csv').values.ravel()\n",
    "\n",
    "print(f\"âœ… Test set cargado: {X_test.shape}\")\n",
    "print(f\"   LegÃ­timas: {(y_test==0).sum()}, Fraudes: {(y_test==1).sum()}\")\n",
    "\n",
    "# Cargar modelos\n",
    "lr_model = joblib.load('../models/lr_model.pkl')\n",
    "rf_model = joblib.load('../models/rf_model.pkl')\n",
    "xgb_model = joblib.load('../models/xgb_model.pkl')\n",
    "\n",
    "print(f\"âœ… Modelos cargados:\")\n",
    "print(f\"   - Logistic Regression\")\n",
    "print(f\"   - Random Forest\")\n",
    "print(f\"   - XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f39203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] Generando predicciones...\n",
      "\n",
      "âœ… Predicciones generadas\n",
      "   LR  - ROC-AUC: 0.9714, F1: 0.1192\n",
      "   RF  - ROC-AUC: 0.9591, F1: 0.7914\n",
      "   XGB - ROC-AUC: 0.9745, F1: 0.8357\n",
      "\n",
      "ðŸ† MEJOR MODELO: XGBoost\n",
      "   ROC-AUC: 0.9745\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. PREDICCIONES CON LOS 3 MODELOS\n",
    "# ============================================================================\n",
    "print(\"\\n[2] Generando predicciones...\")\n",
    "\n",
    "# LR\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_lr = (y_pred_proba_lr >= 0.5).astype(int)\n",
    "roc_auc_lr = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "\n",
    "# RF\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf = (y_pred_proba_rf >= 0.5).astype(int)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "\n",
    "# XGB\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_xgb = (y_pred_proba_xgb >= 0.5).astype(int)\n",
    "roc_auc_xgb = roc_auc_score(y_test, y_pred_proba_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"\\nâœ… Predicciones generadas\")\n",
    "print(f\"   LR  - ROC-AUC: {roc_auc_lr:.4f}, F1: {f1_lr:.4f}\")\n",
    "print(f\"   RF  - ROC-AUC: {roc_auc_rf:.4f}, F1: {f1_rf:.4f}\")\n",
    "print(f\"   XGB - ROC-AUC: {roc_auc_xgb:.4f}, F1: {f1_xgb:.4f}\")\n",
    "\n",
    "# Identificar mejor modelo\n",
    "best_scores = [roc_auc_lr, roc_auc_rf, roc_auc_xgb]\n",
    "best_model_idx = np.argmax(best_scores)\n",
    "best_model_name = ['Logistic Regression', 'Random Forest', 'XGBoost'][best_model_idx]\n",
    "y_pred_proba_best = [y_pred_proba_lr, y_pred_proba_rf, y_pred_proba_xgb][best_model_idx]\n",
    "y_pred_best = [y_pred_lr, y_pred_rf, y_pred_xgb][best_model_idx]\n",
    "best_roc_auc = best_scores[best_model_idx]\n",
    "\n",
    "print(f\"\\nðŸ† MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"   ROC-AUC: {best_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23be4483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3] Optimizando threshold...\n",
      "âœ… Threshold Ã³ptimo encontrado: 0.88\n",
      "   F1-Score Ã³ptimo: 0.8519\n",
      "\n",
      "   MÃ©tricas con threshold Ã³ptimo:\n",
      "   ROC-AUC: 0.9745\n",
      "   F1: 0.8519\n",
      "   Precision: 0.9426\n",
      "   Recall: 0.7770\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. THRESHOLD OPTIMIZATION\n",
    "# ============================================================================\n",
    "print(\"\\n[3] Optimizando threshold...\")\n",
    "\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba_best >= thresh).astype(int)\n",
    "    \n",
    "    if (y_pred_thresh == 1).sum() == 0:\n",
    "        f1_scores.append(0)\n",
    "        precisions.append(0)\n",
    "        recalls.append(0)\n",
    "    else:\n",
    "        f1_scores.append(f1_score(y_test, y_pred_thresh, zero_division=0))\n",
    "        precisions.append(precision_score(y_test, y_pred_thresh, zero_division=0))\n",
    "        recalls.append(recall_score(y_test, y_pred_thresh, zero_division=0))\n",
    "\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "optimal_f1 = f1_scores[optimal_idx]\n",
    "\n",
    "print(f\"âœ… Threshold Ã³ptimo encontrado: {optimal_threshold:.2f}\")\n",
    "print(f\"   F1-Score Ã³ptimo: {optimal_f1:.4f}\")\n",
    "\n",
    "# PredicciÃ³n con threshold Ã³ptimo\n",
    "y_pred_optimal = (y_pred_proba_best >= optimal_threshold).astype(int)\n",
    "roc_auc_optimal = roc_auc_score(y_test, y_pred_proba_best)\n",
    "f1_optimal = f1_score(y_test, y_pred_optimal)\n",
    "precision_optimal = precision_score(y_test, y_pred_optimal)\n",
    "recall_optimal = recall_score(y_test, y_pred_optimal)\n",
    "\n",
    "print(f\"\\n   MÃ©tricas con threshold Ã³ptimo:\")\n",
    "print(f\"   ROC-AUC: {roc_auc_optimal:.4f}\")\n",
    "print(f\"   F1: {f1_optimal:.4f}\")\n",
    "print(f\"   Precision: {precision_optimal:.4f}\")\n",
    "print(f\"   Recall: {recall_optimal:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b40a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4] Creando visualizaciones...\n",
      "   âœ… 10_evaluation_complete.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. VISUALIZACIONES\n",
    "# ============================================================================\n",
    "print(\"\\n[4] Creando visualizaciones...\")\n",
    "\n",
    "# ROC CURVES\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# ROC Curves\n",
    "ax = axes[0, 0]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_proba_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_pred_proba_xgb)\n",
    "\n",
    "ax.plot(fpr_lr, tpr_lr, label=f'LR (AUC={roc_auc_lr:.4f})', linewidth=2)\n",
    "ax.plot(fpr_rf, tpr_rf, label=f'RF (AUC={roc_auc_rf:.4f})', linewidth=2)\n",
    "ax.plot(fpr_xgb, tpr_xgb, label=f'XGB (AUC={roc_auc_xgb:.4f})', linewidth=3)\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves - All Models')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "ax = axes[0, 1]\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba_best)\n",
    "ax.plot(recall_curve, precision_curve, linewidth=2, color='blue')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_title(f'Precision-Recall Curve - {best_model_name}')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Threshold vs F1\n",
    "ax = axes[1, 0]\n",
    "ax.plot(thresholds, f1_scores, linewidth=2, label='F1-Score', color='green')\n",
    "ax.axvline(optimal_threshold, color='red', linestyle='--', linewidth=2, label=f'Optimal ({optimal_threshold:.2f})')\n",
    "ax.set_xlabel('Threshold')\n",
    "ax.set_ylabel('F1-Score')\n",
    "ax.set_title('F1-Score vs Threshold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Confusion Matrix (Threshold Ã³ptimo)\n",
    "ax = axes[1, 1]\n",
    "cm = confusion_matrix(y_test, y_pred_optimal)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, cbar=False)\n",
    "ax.set_xlabel('PredicciÃ³n')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title(f'Confusion Matrix - {best_model_name} (Optimal Threshold)')\n",
    "ax.set_xticklabels(['LegÃ­timo', 'Fraude'])\n",
    "ax.set_yticklabels(['LegÃ­timo', 'Fraude'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/resources/images/10_evaluation_complete.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"   âœ… 10_evaluation_complete.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48058118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5] Classification Report...\n",
      "\n",
      "======================================================================\n",
      "Classification Report - XGBoost (Threshold: 0.88)\n",
      "======================================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      1.00      1.00     85295\n",
      "       Fraud       0.94      0.78      0.85       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.89      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 5. CLASSIFICATION REPORT\n",
    "# ============================================================================\n",
    "print(\"\\n[5] Classification Report...\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Classification Report - {best_model_name} (Threshold: {optimal_threshold:.2f})\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "print(classification_report(y_test, y_pred_optimal, target_names=['Legitimate', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "239f52c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6] MÃ©tricas detalladas...\n",
      "\n",
      "Matriz de ConfusiÃ³n:\n",
      "   TP (Verdaderos Positivos): 115\n",
      "   TN (Verdaderos Negativos): 85288\n",
      "   FP (Falsos Positivos): 7\n",
      "   FN (Falsos Negativos): 33\n",
      "\n",
      "MÃ©tricas de Rendimiento:\n",
      "   Accuracy: 0.9995\n",
      "   Sensitivity (Recall): 0.7770\n",
      "   Specificity: 0.9999\n",
      "   False Positive Rate: 0.0001\n",
      "   False Negative Rate: 0.2230\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 6. DETAILED METRICS\n",
    "# ============================================================================\n",
    "print(\"\\n[6] MÃ©tricas detalladas...\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_optimal)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(f\"\\nMatriz de ConfusiÃ³n:\")\n",
    "print(f\"   TP (Verdaderos Positivos): {tp}\")\n",
    "print(f\"   TN (Verdaderos Negativos): {tn}\")\n",
    "print(f\"   FP (Falsos Positivos): {fp}\")\n",
    "print(f\"   FN (Falsos Negativos): {fn}\")\n",
    "\n",
    "print(f\"\\nMÃ©tricas de Rendimiento:\")\n",
    "print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "print(f\"   Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"   Specificity: {specificity:.4f}\")\n",
    "print(f\"   False Positive Rate: {fpr:.4f}\")\n",
    "print(f\"   False Negative Rate: {fnr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc6ad6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7] Guardando reporte final...\n",
      "   âœ… reports/final_results.md\n",
      "\n",
      "======================================================================\n",
      "âœ… EVALUATION COMPLETADO\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š RESULTADOS FINALES:\n",
      "\n",
      "   ðŸ† MEJOR MODELO: XGBoost\n",
      "      ROC-AUC: 0.9745\n",
      "      F1-Score: 0.8519\n",
      "      Precision: 0.9426\n",
      "      Recall: 0.7770\n",
      "\n",
      "   ðŸŽ¯ THRESHOLD Ã“PTIMO: 0.88\n",
      "      F1 en threshold Ã³ptimo: 0.8519\n",
      "\n",
      "   ðŸ“ VisualizaciÃ³n:\n",
      "      âœ“ reports/resources/images/10_evaluation_complete.png\n",
      "\n",
      "   ðŸ“„ DocumentaciÃ³n:\n",
      "      âœ“ reports/final_results.md\n",
      "\n",
      "   âœ… TARGET ALCANZADO: SI (ROC-AUC > 0.95)\n",
      "\n",
      "ðŸŽ¯ SIGUIENTE: Crear API y tests (opcional pero recomendado)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 7. GUARDAR REPORTE FINAL\n",
    "# ============================================================================\n",
    "print(\"\\n[7] Guardando reporte final...\")\n",
    "\n",
    "reporte_final = f\"\"\"# Final Evaluation Report\n",
    "\n",
    "## Best Model: {best_model_name}\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "- **ROC-AUC:** {best_roc_auc:.4f}\n",
    "- **F1-Score:** {f1_optimal:.4f}\n",
    "- **Precision:** {precision_optimal:.4f}\n",
    "- **Recall:** {recall_optimal:.4f}\n",
    "- **Accuracy:** {accuracy:.4f}\n",
    "\n",
    "### Threshold Optimization\n",
    "- **Optimal Threshold:** {optimal_threshold:.2f}\n",
    "- **F1-Score at Optimal:** {optimal_f1:.4f}\n",
    "\n",
    "### Confusion Matrix\n",
    "| | Predicted Legitimate | Predicted Fraud |\n",
    "|---|---|---|\n",
    "| Actual Legitimate | {tn} | {fp} |\n",
    "| Actual Fraud | {fn} | {tp} |\n",
    "\n",
    "### Detailed Metrics\n",
    "- **True Negatives:** {tn}\n",
    "- **True Positives:** {tp}\n",
    "- **False Positives:** {fp}\n",
    "- **False Negatives:** {fn}\n",
    "- **Sensitivity (TPR):** {sensitivity:.4f}\n",
    "- **Specificity (TNR):** {specificity:.4f}\n",
    "- **False Positive Rate:** {fpr:.4f}\n",
    "- **False Negative Rate:** {fnr:.4f}\n",
    "\n",
    "### Model Comparison (ROC-AUC on Test Set)\n",
    "| Model | ROC-AUC | F1-Score | Precision | Recall |\n",
    "|-------|---------|----------|-----------|--------|\n",
    "| Logistic Regression | {roc_auc_lr:.4f} | {f1_lr:.4f} | {precision_lr:.4f} | {recall_lr:.4f} |\n",
    "| Random Forest | {roc_auc_rf:.4f} | {f1_rf:.4f} | {precision_rf:.4f} | {recall_rf:.4f} |\n",
    "| XGBoost | {roc_auc_xgb:.4f} | {f1_xgb:.4f} | {precision_xgb:.4f} | {recall_xgb:.4f} |\n",
    "\n",
    "### Artifacts Generated\n",
    "- Visualizations: `reports/resources/images/10_evaluation_complete.png`\n",
    "- This report: `reports/final_results.md`\n",
    "\n",
    "### Conclusions\n",
    "- Target ROC-AUC (> 0.95): {\"ACHIEVED\" if best_roc_auc > 0.95 else \"NOT ACHIEVED\"}\n",
    "- Best threshold found: {optimal_threshold:.2f}\n",
    "- Model is ready for deployment\n",
    "\"\"\"\n",
    "\n",
    "with open('../reports/final_results.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(reporte_final)\n",
    "\n",
    "print(\"   âœ… reports/final_results.md\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… EVALUATION COMPLETADO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "ðŸ“Š RESULTADOS FINALES:\n",
    "\n",
    "   ðŸ† MEJOR MODELO: {best_model_name}\n",
    "      ROC-AUC: {best_roc_auc:.4f}\n",
    "      F1-Score: {f1_optimal:.4f}\n",
    "      Precision: {precision_optimal:.4f}\n",
    "      Recall: {recall_optimal:.4f}\n",
    "\n",
    "   ðŸŽ¯ THRESHOLD Ã“PTIMO: {optimal_threshold:.2f}\n",
    "      F1 en threshold Ã³ptimo: {optimal_f1:.4f}\n",
    "\n",
    "   ðŸ“ VisualizaciÃ³n:\n",
    "      âœ“ reports/resources/images/10_evaluation_complete.png\n",
    "\n",
    "   ðŸ“„ DocumentaciÃ³n:\n",
    "      âœ“ reports/final_results.md\n",
    "\n",
    "   âœ… TARGET ALCANZADO: {\"SI\" if best_roc_auc > 0.95 else \"NO\"} (ROC-AUC > 0.95)\n",
    "\n",
    "ðŸŽ¯ SIGUIENTE: Crear API y tests (opcional pero recomendado)\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
